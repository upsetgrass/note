畅课app

[畅课网站](lms.szu.edu.cn)

![image-20250909091907026](https://raw.githubusercontent.com/upsetgrass/typora_pic_bed/main/image-20250909091907026.png)

![image-20250909091941631](https://raw.githubusercontent.com/upsetgrass/typora_pic_bed/main/image-20250909091941631.png)

![image-20250909092012140](https://raw.githubusercontent.com/upsetgrass/typora_pic_bed/main/image-20250909092012140.png)

应用 - 算法 - 语言 - 操作系统 - 指令集 - 微结构 - 电路 - 器件（晶体管） - 物理实现（硅片）

电路：
控制器 时序逻辑？
运算器 组合逻辑？
怎么变成 数字逻辑电路？



高通（小米） 华为 苹果实现arm架构

intel amd 实现x86架构



多核：一核有难八核围观

多核解决同一个问题

数据级并行 线程级并行



幻灯片本身就可以知道讲解内容，讲解是用于深入的



开题答辩、预答辩 10分钟

正式答辩 <25分钟





# 第一次课程

按下一次键盘，程序的运行和晶体管电子流动之间的关系？

经历了哪些过程？应用程序→操作系统→硬件系统→处理器→晶体管？

上述过程中涉及到的量化指标（性能、功耗、成本）的关系？

什么是计算机体系结构？



指令集：完备性，找到能够满足所有需求的一批基本操作

x86 - 桌面、服务器

arm - 移动互联，追求功耗（性能有限转换成功耗有限） 20%的指令集完成ISA架构

兼容性问题导致后续没有出现其他的架构

ISA：RISC、CISC->transmeta、itanium、虚拟机





# 第二次课程

并行：协同完成一个共同任务

并行难：分解难（依赖关系）

- 指令并行

IPC CPI衡量并行程度

流水线 多发射都是指令并行

- 数据级并行：

硬件为了更好的应用：

音频视频等多媒体数据的需求很大，就出现了数据级并行

对数据的操作都是一样的，天然的支持并行，intel mmx（多媒体扩展）

前二十帧给核1   后面二十帧给核2....（分解数据）

- 线程级并行：

数据不大，对数据操作的任务较复杂，分解复杂任务，线程相互独立



现代的计算机都是带有数据级并行、线程级并行的硬件



下面这两个并不是真正的并行，并不是协同完成一个共同任务

任务级（进程级）并行

作业级（程序级）并行



集群：多个处理器构成的系统

处理器：多个核构成的系统



TP-计算机 TN-电子



并行程序只能提高可并行部分，串行部分不可并行，以此判断一个程序的并行加速上限，一般来说无限的提高并行程度并没有太大的收益（收益随着并行程度递减）





流水处理加速

独立任务之间并行执行，本质：提升带宽  

指令流水：取值 译码 执行 访存 写回 ，这五个步骤相对独立，并且所需要的资源是独立的  DDR4 DDR5  有些程序是带宽敏感、有些程序是延迟敏感 （增加带宽必定带来单条指令延迟）

流水线的代价：单条指令执行的时间增加（各级所需时间不相等）？

但是指令之间会有大量的依赖：所以指令流水并不能全部功能部件运行

流水线的加速比







分支预测，通过预测提高性能，是做在硬件上

- 转移猜测

  指令的预测，分支预测（跳转问题）会影响流水线的性能，

  平均4-6条指令有一条分支指令 --- plugin

  猜测分支1）是否能够跳转 2）跳转的地址在哪（目前能够做到：95%-98%的准确性）

  如何猜？基于已有的信息，判断：倾向于跳还是不跳，判断跳转的地址

  猜测正确，那就正常执行，猜测错误，流水线需要刷新

  分支预测虽然现在已经到98%，但是每提高0.1%，也都是有意义的，10000条指令能够减少10次流水级的刷新

  针对新的应用和新的结构，会有不同的预测机制技术

  有序数组的执行效率会高于随机数组的执行效率（无序的分支预测效率很低），无序转成有序（会有很多方法）- 硬件亲和

  

  

- 高速缓存

  数据的预测





基于无序和有序的同样操作，性能可以提升：10%

处理器的速度越来越快

处理器层次化原理

内存（电容来做，充放电状态）

memory性能和处理器性能差异越来越大，因而把一部分memory用晶体管放到了cpu里面，称为高速缓存

因而现代的cpu＝运算 + 逻辑 + 高速缓存



利用层次化，运算 逻辑 和三级缓存 然后再是内存

局部性原理，程序访问都是地址空间较小的一部分内容（时间局部性，空间局部性）

存储器技术（缓存SRAM（贵，基于晶体管）  主存DRAM（基于电容）d是动态，电容的物理性质使得存储的信息不稳定，需要经常刷新）

100次访问,99次都可以在三级高速缓存中找到（命中），没有找到就是miss，现在一般能做到95以上

高速缓存的透明性质

高速缓存接受的是主存的地址（高速缓存一行就是一个结构体，实际数据＋主存地址标记）

更改布局：key[]   value[]  和struct{key，value}后者的命中率能够提高，效率更高

矩阵乘法，转置一下...

矩阵分块...  数据的布局排列，根据高速缓存的容量和局部性原理





冗余技术

提高了计算机系统可靠当部分出现故障时系统仍然能正常

谷歌的冗余存储hadoop HDFS ，用软件的冗余性增加技术的可靠性，用较少的成本达到服务器

服务器贵-可靠性很高，容错性很高

一个核die了，还有其他核顶上



isa层次以上软件，isa层次以下硬件



微结构公司intel amd

amd更有创新型（多核技术.... gpu集成  核数  高速缓存容量）

intel是老大，然后就照抄amd

器件层面，台积电（绝对的王者！）

台积电受美国公约，不能给中国最新的工艺，还有EDA也要限制

计算机中信息（数）的表示





数据需求的量级

int long float double的精度比较

long > double > int >  float？

数据一定和处理的指令一起，指令决定了处理的数据是什么

数值型数据（整数，浮点数）

非数值型数据（逻辑数据，编码字符）

约定好小数点位置（定点数）






# 第三次课

类型转换，精度丢失问题、截断问题





晶体管：构成计算机的最基本单位-实现0和1的切换，也就是开关

由开关构成逻辑门（AND OR  NOT）

逻辑门设计出逻辑电路（加法器、逻辑器、时序逻辑、...）

逻辑电路设计微处理器部件

微处理器部件结合成微处理器架构



MOS金属氧化半导体 p-MOS（拉高-导入正极）  n-MOS（拉低-导入负极） p-MOS n-MOS成对出现      *是否会出现短路？*

反门 - 一对MOS即可实现

两对MOS可以构建与非门（四个晶体管）、或非门（四个晶体管）、与门（六个晶体管）、或门（六个晶体管）





# 第四次课

量子计算机（计算降维 不具有可编程性  只能针对特定算法设计特定的量子计算机） 


dna计算机（生化反应  高度并行）





计算机体系的量化性能指标：

什么算是好？

庞大ISA和精简ISA

精简ISA硬件的带来的简化与软件模拟大多数不常用指令带来的性能下降的比较

数据集并行（DLP）现在取得了很好的效果



# 第五次课

带宽 吞吐量

台积电的7 5 3纳米：纳米代号
intel不希望用纳米代号：intel7工艺
现在很难继续把晶体管做小了

PPA指标（power performance area）

PPA指标（power performance area）是评价芯片的指标
power - 能耗，使用成本
performance -算法性能
area - 面积

功耗 面积还不是最厉害的

能耗（功率和时间决定）

晶体管 就是一个开关，晶体管做的越来越小，绝缘材料越来越薄，阻抗越来越小，使得关闭晶体管的时间依旧有一定的电流，而不是完全的阻断
使得一段时间电脑不用，电量也会下降





# 第六次课

![image-20251014090117801](../../pic_to_typora/image-20251014090117801.png)

Inst.Count - X86 CISC-大量的指令类型，相同的功能，其能够用较少的指令数完成，优秀的编译器（更紧凑的编译）-Compiler，优秀的算法-Program



CPI RISC架构，指令较为规整，利于设计流水线，每条指令完成的时间更少，

CPI（Average Cycles per Instruction） eg：每条指令完成需要1.4时钟周期

Clock Rate - 时钟频率-工艺推动



提高IPC（Average Instruction per Cycles）充分利用并行、局部性原理、阿姆达定理（Amdahl）（去寻找关键的指令，占比更大的指令时间，更有必要去做优化）  可并行的部分占10%，最多也就提升到原来性能的90%，不能只谈加速部分的加速，需要谈对整体的加速

![image-20251014092945711](../../pic_to_typora/image-20251014092945711.png)



存储器层次结构

很多重大突破都是在这里做研究

存储器的发展跟不上处理器的发展，所以现在还有很多可研究的点

主频、高速缓存对性能影响很大（缓存容量很关键） 晶体管的速度远高于电容充放电，（核数量影响不大）

手机上-flush存储  台式-磁存储，容量大  冷热盘（热盘-flush盘  冷盘-磁盘）



高速缓存的量化



# 第七次课

高速缓存能达到90%的命中率，很少会直接使用到主存



一次性取多少从主存到缓存，一次取多少，就是一个cache line（临近数据）

|有效位valid|地址标记tag-地址高位（低位就是line部分）|数据拷贝|



缓存空间满了，又来了新的，替换哪一行？空间局部性、时间局部性

1）任意选择（需要访问所有的block基本块）

2）直接映射（直接通过取模运算，直接映射到指定block）

3）多组相连（取模得到到哪个组的信息，然后组内访问作比较，一般会选择组内四个block，很少会遇到组内四个block都是热点，这样只需要四个比较器）



Cache替换算法：

LRU-最近最少使用的数据离开   每个cache中加一个计数器，每次访问就计数器+1，并且在一个时间片里面清零（防止计数器很大，但是最近访问比较少-历史积累）  —— 当前最好的算法，也有很多其他算法对LRU算法进行优化

FIFO-最先进最先出



CPU给高速缓存写数据，高速缓存不给主存写数据，即不写回，在单核影响不大，主要在多核影响大，会有不一致的问题，所有有下面这个方法



写穿透（Write Through）（写Cache的同时，直接写到主存，管理简单）

L1到L2用写穿透的多，L2还是较快，但是L2到主存比较少



写分配：写命中时采用写会策略

写不分配：写Cache失效时，采用



缺失（miss）当要访问数据在高速缓存中没有找到，就产生了所谓的缺失

- 强制性缺失：首次访问，不可避免

- 容量缺失：cache中加载新数据块时需要替换已有数据块- 容量大，容量缺失率低
- 冲突缺失：不同Cache块由于index相同引起冲突失效
- 一致性缺失：一致性开销引起的缺失（失效）



Cache性能分析：

AMAT（Average Memory Access Time）

AMAT=HitTime+Penaltytime（惩罚时间）= HitTime+MissRate×penaltytime    （hittime小->容量小好，容量小又会提高MissRate   -> **trande off**权衡  PenaltyTime-主存性能-主存技术）

服务器一般L1 L2 L3

个人PC一般L1 L2

L1 128K 256K  -> 必须小，保证hittime用时少，L2 保证缺失率不会太高...

L3 几十MB



降低失效率：

- 增加块Cacheline大小
- 增加Caceh容量（主导）
- 增加相连数目
- 路预测（Way Prediction）-
- 软件优化



访存的流水线是最慢的



$CPI_{ALUOps}$不包含访存指令



AMD做的高速缓存的容量越来越高，核数也更多，价格还和intel差不多



分支预测正确率可以做到98% 98.5%



通过编译器（软件）优化降低失效率

知道cache的特性后，用编译器来优化，几倍几十倍的收益（矩阵运算...）

 



处理器的95%的价格都在高速缓存，主要是其容量

HBM(High Bandwidth Memory) -M1芯片  牺牲灵活性，把内存和CPU做在一起



虚拟内存

TLB-页表的Cache



流水线-指令重叠技术



指令级并行：乱序——指令依赖关系，后续指令不依赖前序指令，....

同时取多条，分析依赖关系

香山98%





# x



动态流水线：有序进入、乱序执行、有序结束

保留站-发射队列，顺序->乱序执行

ROB(Reorder Buffer) 把乱序变为有序

issue-发射-把指令送到执行部件

多发射：允许一个时钟周期内送多条指令到执行部件

目前的技术：多发射：6-8条



超标量处理器：具有多发射能力的处理器（四路、六路、八路）



超长指令字（very long instruction word, VLIW)多条指令凭借为一条指令-软件方案

- 静态指令超长字-以前的设计，现在很少用了



intel官网有SIMD指令C调用